#! /usr/bin/env python
# -*- coding: utf-8 -*-
#
# グリッドサーチを用いてパラメータの値を決定する
# 「from sklearn.grid_search import GridSearchCV」
#
# 学習データとテストデータを分ける場合は以下も必要
# 「from sklearn.cross_validation import train_test_split」
#
# 注記）もっと効率の良い探索方法があるはず
#
# 作成開始日：2018年 5月31日（木)
# 最終修正日：2018年 5月29日（火）

import sys
import numpy as np
import matplotlib.pyplot as plt
from nilearn.input_data import NiftiMasker
from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline
from sklearn.cross_validation import cross_val_score
from sklearn import decomposition
from sklearn.decomposition import PCA
from nilearn.plotting import plot_stat_map, show
import nibabel as nib
from nilearn import plotting
from sklearn.grid_search import GridSearchCV
import datetime

# Main function
def main():
argvs = sys.argv    # コマンドライン引数を格納したリストの取得
argc = len(argvs)    # 引数の個数

# Input from command-line interface
if (argc != 4):
print('Usage: python Structure_SVR_05.py In_StructureList(**.txt) In_Parameter(**.txt) Out_Fig(**.png)')
quit()


##### Start time
print(" ")
startDateTime = datetime.datetime.today()
print("Start : " + str(startDateTime))



##### Read input data from files

# File open
finStructure = open(argvs[1], 'r')
finParam = open(argvs[2], 'r')

# Read file name of Structure
# Type of listStructure : list
NameStructure = []
for file in finStructure:
NameStructure.append(file.rstrip("\n"))                            # NameStructure.append(file)だと改行コードがリストに入ってしまう

# Number of subjects
n_subjects = len(NameStructure)
print(" ")
print("Check number of parameters")
print("%d subjects" % (n_subjects))                                    # To check

# Read value of parameter
# Type of valueParam : ndarray NumPy配列
valueParam_list = []                                                    # read as list
for file in finParam:
valueParam_list.append(file.rstrip("\n"))
valueParam = np.array(valueParam_list).astype(np.float)                # np.array() : list -> ndarray, astype(np.float) : numeric type

# File close
finStructure.close()
finParam.close()



#####  Preprocess of Structure data

# Masking: 4 dim -> 2 dim for analysis with NumPy
nifti_masker = NiftiMasker(standardize=False, smoothing_fwhm=2, memory='nilearn_cache')
dataStructure = nifti_masker.fit_transform(NameStructure)            # Two dimensional ndarray for analysis with NumPy library

# Check
n_samples, n_features = dataStructure.shape                            # Shape of gm_maps_masked : [n_samples,n_features]
print("%d samples, %d features" % (n_subjects, n_features))            # To check
print(" ")



##### Pipeline with PCA


# pca
feature_selection = decomposition.PCA
pca_t=pca.fit(dataStructure)
dataStructure_reduced = inc_pca.transform(dataStructure_train)#splited?

# k value is determined by cross-validation

# SVR
# kernel : Specifies the kernel type to be used in the algorithm, default=’rbf’
# C : Penalty parameter C of the error term, default=1.0
# epsilon : Epsilon in the epsilon-SVR model, default=0.1
svr = SVR(kernel='linear')                                                            # kernel, C, and epsilon are determined by cross-validation

# feature selection (SelectKBest) and predictor (SVR) are plugged together with pipeline
pca_svr_GS = Pipeline([
('pca', feature_selection),
('svr', svr)
])



##### Gridsearch

# parameters to be estimated
parameters = [{
'pca__k' : [400, 700, 1000, 2000, 4000, 7000, 10000],
'svr__C' : [0.4, 0.7, 1.0, 2.0, 4.0],
'svr__epsilon' : [0.04, 0.07, 0.1, 0.2, 0.4]
}]

# Grid search
pca_svr_GSCV = GridSearchCV(pca_svr_GS, parameters, cv=5, n_jobs=-1)
pca_svr_GSCV.fit(dataStructure, valueParam)



##### Pipeline with Best parameters

# A classical univariate feature selection based on F-test, namely ANOVA
feature_selection = SelectKBest(?, k=pca_svr_GSCV.best_params_['pca__k'])

# SVR
svr = SVR(kernel='linear', C=pca_svr_GSCV.best_params_['svr__C'], epsilon=pca_svr_GSCV.best_params_['svr__epsilon'])

# feature selection (SelectKBest) and predictor (SVR) are plugged together with pipeline
anova_svr_bestP = Pipeline([
('pca', feature_selection),
('svr', svr)
])



##### Model estimation (fit) and prediction (predict)

# Model estimation
pca_svr_bestP.fit(dataStructure, valueParam)

# Prediction
predictedParam = pca_svr_bestP.predict(dataStructure)



##### Cross validation (CV)

# cross-validation
cv_scores = cross_val_score(pca_svr_bestP, dataStructure, valueParam, cv=5, n_jobs=-1)
print("Prediction accuracy at each fold")
print(cv_scores)

# Mean prediction accuracy
prediction_accuracy = np.mean(cv_scores)
print("Mean prediction accuracy: %f" % prediction_accuracy)
print(" ")



##### Visualization

# Inverse transformation of coefficient
coef = svr.coef_
coef = inc_pca.inverse_transform(coef)                   # reverse feature selection
weight_img = nifti_masker.inverse_transform(coef)                    # reverse masking

# Create the figure
plotting.plot_glass_brain(weight_img, threshold=0, colorbar=True, plot_abs=False)



##### Save results

# parameters
print(" ")
print("PCA_dim : " + str(pca_svr_GSCV.best_params_['pca__k']))
print("SVR_C : " + str(anova_svr_GSCV.best_params_['svr__C']))
print("SVR_epsilon : " + str(anova_svr_GSCV.best_params_['svr__epsilon']))

# save as png
plt.savefig(argvs[3] + ".png")

# save NIfTI
nib.save(weight_img, argvs[3] + ".nii.gz")



##### End time
print(" ")
endDateTime = datetime.datetime.today()
print("End : " + str(endDateTime))
print("Calculation time : " + str(endDateTime - startDateTime))
print(" ")



# The first function to be run
if __name__ == "__main__":
main()

